{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "ea65b84c",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "import cv2\n",
    "from tqdm import tqdm"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bee20da6",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "de5f8474",
   "metadata": {},
   "outputs": [],
   "source": [
    "DATADIR = \"./data/\"\n",
    "CATEGORIES = [\"Cat\", \"Dog\"]\n",
    "IMG_SIZE = 100"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "feb49eb5",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "5a7be07c",
   "metadata": {},
   "outputs": [],
   "source": [
    "training_data = []"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8a5111e9",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "452ca1df",
   "metadata": {},
   "outputs": [],
   "source": [
    "MAX_IMAGES_PER_CLASS = 5000  # ou 500, por exemplo\n",
    "\n",
    "def create_training_data():\n",
    "    for category in CATEGORIES:\n",
    "        path = os.path.join(DATADIR, category.lower())\n",
    "        class_num = CATEGORIES.index(category)\n",
    "        count = 0\n",
    "        for img in tqdm(os.listdir(path)):\n",
    "            if count >= MAX_IMAGES_PER_CLASS:\n",
    "                break\n",
    "            try:\n",
    "                img_array = cv2.imread(os.path.join(path, img), cv2.IMREAD_COLOR)\n",
    "                new_array = cv2.resize(img_array, (IMG_SIZE, IMG_SIZE))\n",
    "                training_data.append([new_array, class_num])\n",
    "                count += 1\n",
    "            except Exception:\n",
    "                pass\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ca9bdef8",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "9171aba3",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 40%|‚ñà‚ñà‚ñà‚ñà      | 5001/12501 [01:26<02:09, 58.00it/s]\n",
      " 40%|‚ñà‚ñà‚ñà‚ñà      | 5001/12501 [01:16<01:54, 65.61it/s] \n"
     ]
    }
   ],
   "source": [
    "create_training_data()\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8547837a",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "433846f9",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "1a8b56aa",
   "metadata": {},
   "outputs": [],
   "source": [
    "import random\n",
    "\n",
    "random.shuffle(training_data)\n",
    "\n",
    "x = []\n",
    "y = []\n",
    "\n",
    "for features, label in training_data:\n",
    "    x.append(features)\n",
    "    y.append(label)\n",
    "\n",
    "x = np.array(x).reshape(-1, IMG_SIZE, IMG_SIZE, 3) / 255.0\n",
    "y = np.array(y)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2fd578b6",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c4df0f2b",
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Conv2D, MaxPooling2D, Flatten, Dense, Dropout\n",
    "\n",
    "model = Sequential()\n",
    "\n",
    "model.add(Conv2D(32, (3, 3), activation='relu', input_shape=(IMG_SIZE, IMG_SIZE, 3)))\n",
    "model.add(MaxPooling2D(pool_size=(2, 2)))\n",
    "\n",
    "model.add(Conv2D(64, (3, 3), activation='relu'))\n",
    "model.add(MaxPooling2D(pool_size=(2, 2)))\n",
    "\n",
    "model.add(Flatten())\n",
    "model.add(Dense(64, activation='relu'))\n",
    "model.add(Dropout(0.5))  \n",
    "model.add(Dense(1, activation='sigmoid')) \n",
    "\n",
    "model.compile(optimizer='adam',\n",
    "              loss='binary_crossentropy',\n",
    "              metrics=['accuracy'])\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "46404fec",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "35703a32",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "250/250 [==============================] - 53s 176ms/step - loss: 0.6797 - accuracy: 0.5824 - val_loss: 0.6574 - val_accuracy: 0.6285\n",
      "Epoch 2/10\n",
      "250/250 [==============================] - 42s 170ms/step - loss: 0.6075 - accuracy: 0.6721 - val_loss: 0.5934 - val_accuracy: 0.6815\n",
      "Epoch 3/10\n",
      "250/250 [==============================] - 45s 179ms/step - loss: 0.5333 - accuracy: 0.7331 - val_loss: 0.5390 - val_accuracy: 0.7260\n",
      "Epoch 4/10\n",
      "250/250 [==============================] - 44s 175ms/step - loss: 0.4667 - accuracy: 0.7830 - val_loss: 0.5307 - val_accuracy: 0.7330\n",
      "Epoch 5/10\n",
      "250/250 [==============================] - 43s 174ms/step - loss: 0.4021 - accuracy: 0.8170 - val_loss: 0.6250 - val_accuracy: 0.7180\n",
      "Epoch 6/10\n",
      "250/250 [==============================] - 45s 179ms/step - loss: 0.3280 - accuracy: 0.8583 - val_loss: 0.5467 - val_accuracy: 0.7515\n",
      "Epoch 7/10\n",
      "250/250 [==============================] - 43s 173ms/step - loss: 0.2745 - accuracy: 0.8854 - val_loss: 0.6286 - val_accuracy: 0.7465\n",
      "Epoch 8/10\n",
      "250/250 [==============================] - 44s 177ms/step - loss: 0.1997 - accuracy: 0.9191 - val_loss: 0.7254 - val_accuracy: 0.7525\n",
      "Epoch 9/10\n",
      "250/250 [==============================] - 45s 179ms/step - loss: 0.1600 - accuracy: 0.9399 - val_loss: 0.7146 - val_accuracy: 0.7525\n",
      "Epoch 10/10\n",
      "250/250 [==============================] - 45s 178ms/step - loss: 0.1310 - accuracy: 0.9490 - val_loss: 0.7600 - val_accuracy: 0.7510\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.src.callbacks.History at 0x2d1e927e250>"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.fit(x, y, epochs=10, batch_size=32, validation_split=0.2)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5bd4054d",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "f966cbda",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 0s 104ms/step\n",
      "Cat\n"
     ]
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "def prepare(filepath):\n",
    "    img_array = cv2.imread(filepath)\n",
    "    resized = cv2.resize(img_array, (IMG_SIZE, IMG_SIZE)) / 255.0\n",
    "    return resized.reshape(-1, IMG_SIZE, IMG_SIZE, 3)\n",
    "\n",
    "prediction = model.predict(prepare(\"data/Cat/0.jpg\"))\n",
    "print(\"Dog\" if prediction[0][0] > 0.5 else \"Cat\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9b70f8c8",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "df8e294b",
   "metadata": {},
   "outputs": [],
   "source": [
    "model.save(\"modelo_caes_gatos.keras\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f22994c5",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "2f35f65e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 0s 59ms/step\n",
      "1/1 [==============================] - 0s 44ms/step\n",
      "1/1 [==============================] - 0s 20ms/step\n",
      "1/1 [==============================] - 0s 21ms/step\n",
      "1/1 [==============================] - 0s 21ms/step\n",
      "1/1 [==============================] - 0s 21ms/step\n",
      "1/1 [==============================] - 0s 20ms/step\n",
      "1/1 [==============================] - 0s 19ms/step\n",
      "1/1 [==============================] - 0s 21ms/step\n"
     ]
    }
   ],
   "source": [
    "import tkinter as tk\n",
    "from tkinter import filedialog\n",
    "from PIL import Image, ImageTk, ImageOps\n",
    "import cv2\n",
    "import numpy as np\n",
    "from tensorflow.keras.models import load_model\n",
    "\n",
    "# --- CONFIGURA√á√ïES ---\n",
    "IMG_SIZE = 100\n",
    "MODEL_PATH = \"modelo_caes_gatos.keras\"\n",
    "\n",
    "# --- Carregar modelo ---\n",
    "model = load_model(MODEL_PATH)\n",
    "\n",
    "# --- Fun√ß√£o de Previs√£o ---\n",
    "def prepare_image(filepath):\n",
    "    img = cv2.imread(filepath)\n",
    "    img = cv2.resize(img, (IMG_SIZE, IMG_SIZE)) / 255.0\n",
    "    return img.reshape(-1, IMG_SIZE, IMG_SIZE, 3)\n",
    "\n",
    "def predict_image():\n",
    "    file_path = filedialog.askopenfilename()\n",
    "    if file_path:\n",
    "        # Exibir imagem\n",
    "        img = Image.open(file_path).convert(\"RGB\")\n",
    "        img = ImageOps.fit(img, (250, 250), Image.Resampling.LANCZOS)\n",
    "        img_tk = ImageTk.PhotoImage(img)\n",
    "        image_label.config(image=img_tk)\n",
    "        image_label.image = img_tk\n",
    "\n",
    "        # Prever\n",
    "        prediction = model.predict(prepare_image(file_path))\n",
    "        if prediction[0][0] > 0.5:\n",
    "            result = \"üê∂ √â um cachorro!\"\n",
    "            color = \"#d0f0c0\"\n",
    "        else:\n",
    "            result = \"üê± √â um gato!\"\n",
    "            color = \"#f5c8c8\"\n",
    "\n",
    "        result_label.config(text=result, bg=color)\n",
    "\n",
    "# --- Constru√ß√£o da Interface ---\n",
    "window = tk.Tk()\n",
    "window.title(\"Classificador C√£o vs Gato\")\n",
    "window.geometry(\"350x450\")\n",
    "window.configure(bg=\"#f0f0f0\")\n",
    "\n",
    "title_label = tk.Label(window, text=\"Classificador de C√£es e Gatos\",\n",
    "                       font=(\"Arial\", 14, \"bold\"), bg=\"#f0f0f0\", fg=\"#333\")\n",
    "title_label.pack(pady=10)\n",
    "\n",
    "btn = tk.Button(window, text=\"Escolher Imagem üñºÔ∏è\",\n",
    "                command=predict_image, font=(\"Arial\", 12), bg=\"#4caf50\", fg=\"white\",\n",
    "                activebackground=\"#45a049\", padx=10, pady=5, relief=\"raised\")\n",
    "btn.pack(pady=10)\n",
    "\n",
    "image_label = tk.Label(window, bg=\"#dddddd\", width=250, height=250, bd=2, relief=\"groove\")\n",
    "image_label.pack(pady=10)\n",
    "\n",
    "result_label = tk.Label(window, text=\"Resultado aparecer√° aqui\",\n",
    "                        font=(\"Arial\", 14, \"bold\"), bg=\"#ffffff\", fg=\"#000000\", bd=2,\n",
    "                        relief=\"ridge\", width=25, height=2)\n",
    "result_label.pack(pady=20)\n",
    "\n",
    "window.mainloop()\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "tf-venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
